# Paper

- Title: Event2Mind: Commonsense Inference on Events, Intents, and Reactions
- Authors: Hannah Rashkin, Maarten Sap, Emily Allaway, Noah A. Smith, Yejin Choi
- Link: https://arxiv.org/abs/1805.06939
- Repository: https://github.com/uwnlp/event2mind
- Tags: Datasets, Commonsense
- Year: 2019

# Summary

- What
  
  - A publicly available dataset of ~25k event phrases in short-form text, annotated with intents and reactions.
  - A new task of pragmatic inference, i.e. generating text descriptions of the intents and the reactions (including those of people not explicitly mentioned in the event phrase) to a given event.
  - A baseline for the above task.

- How

  - Dataset
    - Event phrases:
      - The event phrases are extracted from the ROC Story train set, Google Syntactic N-grams and the Spinn3r corpus. This list of events is also supplemented with 2k verb idioms from Wikidictionary. In total, this amounts to almost 25,000 event phrases over 1,300 unique verb predicates.
      - The event phrases are generalised through the use of typed variables (e.g. PersonX, PersonY).
      - The arguments of the verbs are kept in the dataset if they appear frequently enough, otherwise they are replaced with an untyped blank (e.g. PersonX eats __ for dinner).
    - Intents:
      - Intents are written by human annotators. For each even phrase, annotators are asked to write up to 3 descriptions of the agent's (PersonX) intent if the event is classified as intentional.
    - Reactions:
      - Reactions are annotated by crowd workers too. For each event phrase, annotators are asked to write up to 3 possible reactions that the agent (PersonX) might experience, as well as up to 3 possible reactions that other people might experience.

<img src="https://github.com/lisaalaz/papers/blob/master/images/Event2Mind_dataset.png" width="800">
  
  - Task

    Given an event phrase, the objective is to reason about the intents and emotional reactions of the people who caused or were affected by the event. There are two types of inference in this task:
    - __Intent pragmatic inference__, where an intent is an explanation of why the agent caused the event to occur (if the event is voluntary. For involuntary events this is "None"). An intent can be another event, or it can be an action or a mental pre-condition.
    - __Emotional reaction pragmatic inference__, where a reaction is an explanation of how the mental states of the agent and any other person involved in the event change as a result of the event itself.

<img src="https://github.com/lisaalaz/papers/blob/master/images/Event2Mind_task.png" width="400">
  
  - Models
    
    They train encoder-decoder models for the task of - given an event phrase E - generate 3 entity-specific pragmatic inferences $v_i$ (PersonX's intent), $v_x$ (PersonX's reaction) and $v_o$ (other people's reaction).
    - The input E is encoded into an embedding vector $h_E$ of $H$ dimensions. This is then passed into 3 separate decoders, to output $v_i$, $v_x$, and $v_o$ respectively.
    - They experiment with different encoding functions and decoder setups.

- Results

  - They evaluate recall@10 on all their model setups: having generated the top-10 most likely intents and reactions for each example, they look at the proportion of examples where the gold label(s) is present in this top 10.

<img src="https://github.com/lisaalaz/papers/blob/master/images/Event2Mind_aut_eval.png" width="800">

  - They also carry out human evaluation: they randomly select 100 events from the test set they present crowd workers with the top-10 most likely intents and reactions generated by the model for each event. They ask the workers to select all of the ones that seem reasonable/correct, and then acerage these results across each model to calculate precision@10 for that model.

<img src="https://github.com/lisaalaz/papers/blob/master/images/Event2Mind_human_eval.png" width="400">

- Application to movie scripts:
  
  They use their best model on scene descriptions from 772 movie scripts.
  - They first extract the events from the scene descriptions and then generate their 10 most likely intents and reactions.
  - Then they aggregate the generated intents and reactions into groups based on LIWC category scores and also aggregate these by character.
  - They use logistic regression to compute, for each category of intents or reactions, its correlation with gender.
  - They find bias in the intents and reactions assigned characters of different genders that is consistent with observations made in psychology and gender studies literature.

<img src="https://github.com/lisaalaz/papers/blob/master/images/Event2Mind_movies.png" width="400">  
